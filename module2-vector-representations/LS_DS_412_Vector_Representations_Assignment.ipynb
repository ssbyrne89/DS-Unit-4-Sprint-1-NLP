{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Vector Representations\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "## 1) *Clean:* Job Listings from indeed.com that contain the title \"Data Scientist\" \n",
    "\n",
    "You have `job_listings.csv` in the data folder for this module. The text data in the description column is still messy - full of html tags. Use the [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library to clean up this column. You will need to read through the documentation to accomplish this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
       "1           1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
       "2           2  b'<div><p>As a Data Scientist you will be work...   \n",
       "3           3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "4           4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "\n",
       "                          title  \n",
       "0               Data scientist   \n",
       "1              Data Scientist I  \n",
       "2  Data Scientist - Entry Level  \n",
       "3                Data Scientist  \n",
       "4                Data Scientist  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "##### Your Code Here #####\n",
    "\n",
    "df = pd.read_csv(\"./data/job_listings.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over the ['description'] column with BeautifulSoup to clean out html stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"Job Requirements:\\nConceptual understanding ...</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'Job Description\\n\\nAs a Data Scientist 1, yo...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b'As a Data Scientist you will be working on c...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b'$4,969 - $6,756 a monthContractUnder the gen...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b'Location: USA \\xe2\\x80\\x93 multiple location...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  b\"Job Requirements:\\nConceptual understanding ...   \n",
       "1           1  b'Job Description\\n\\nAs a Data Scientist 1, yo...   \n",
       "2           2  b'As a Data Scientist you will be working on c...   \n",
       "3           3  b'$4,969 - $6,756 a monthContractUnder the gen...   \n",
       "4           4  b'Location: USA \\xe2\\x80\\x93 multiple location...   \n",
       "\n",
       "                          title  \n",
       "0               Data scientist   \n",
       "1              Data Scientist I  \n",
       "2  Data Scientist - Entry Level  \n",
       "3                Data Scientist  \n",
       "4                Data Scientist  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for text in df['description']:\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    d.append(soup.get_text())\n",
    "df['description'] = d\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use Spacy to tokenize the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "source": [
    "### doing the same thing, iterating over the cleaned text in df['description'].\n",
    "\n",
    "#### however i will create a new column for lemmas after using spacy to tokenize the documents from df['description']. stop words and punctuation are removed and the rest are lemmatized to create the new column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"Job Requirements:\\nConceptual understanding ...</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>[b\"Job, requirements:\\nconceptual, understandi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'Job Description\\n\\nAs a Data Scientist 1, yo...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>[b'Job, description\\n\\na, Data, scientist, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b'As a Data Scientist you will be working on c...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "      <td>[b'As, Data, scientist, work, consult, busines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b'$4,969 - $6,756 a monthContractUnder the gen...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[b'$4,969, $, 6,756, monthcontractunder, gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b'Location: USA \\xe2\\x80\\x93 multiple location...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[b'Location, USA, \\xe2\\x80\\x93, multiple, loca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  b\"Job Requirements:\\nConceptual understanding ...   \n",
       "1           1  b'Job Description\\n\\nAs a Data Scientist 1, yo...   \n",
       "2           2  b'As a Data Scientist you will be working on c...   \n",
       "3           3  b'$4,969 - $6,756 a monthContractUnder the gen...   \n",
       "4           4  b'Location: USA \\xe2\\x80\\x93 multiple location...   \n",
       "\n",
       "                          title  \\\n",
       "0               Data scientist    \n",
       "1              Data Scientist I   \n",
       "2  Data Scientist - Entry Level   \n",
       "3                Data Scientist   \n",
       "4                Data Scientist   \n",
       "\n",
       "                                               lemma  \n",
       "0  [b\"Job, requirements:\\nconceptual, understandi...  \n",
       "1  [b'Job, description\\n\\na, Data, scientist, 1, ...  \n",
       "2  [b'As, Data, scientist, work, consult, busines...  \n",
       "3  [b'$4,969, $, 6,756, monthcontractunder, gener...  \n",
       "4  [b'Location, USA, \\xe2\\x80\\x93, multiple, loca...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma = []\n",
    "for tx in df['description']:\n",
    "    doc = nlp(tx)\n",
    "    lemma.append([token.lemma_ for token in doc if (token.is_stop != True) and (token.is_punct != True)])\n",
    "df['lemma'] = lemma\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### below shows the columns side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "['b\"Facebook', 'mission', 'people', 'power', 'build']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"Job Requirements:\\nConceptual understanding ...</td>\n",
       "      <td>[b\"Job, requirements:\\nconceptual, understandi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'Job Description\\n\\nAs a Data Scientist 1, yo...</td>\n",
       "      <td>[b'Job, description\\n\\na, Data, scientist, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'As a Data Scientist you will be working on c...</td>\n",
       "      <td>[b'As, Data, scientist, work, consult, busines...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  b\"Job Requirements:\\nConceptual understanding ...   \n",
       "1  b'Job Description\\n\\nAs a Data Scientist 1, yo...   \n",
       "2  b'As a Data Scientist you will be working on c...   \n",
       "\n",
       "                                               lemma  \n",
       "0  [b\"Job, requirements:\\nconceptual, understandi...  \n",
       "1  [b'Job, description\\n\\na, Data, scientist, 1, ...  \n",
       "2  [b'As, Data, scientist, work, consult, busines...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(df[['description', 'lemma']]))\n",
    "print(df['lemma'][301][0:5])\n",
    "df[['description', 'lemma']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### below, I'm instantiating the CountVectorizer class with a 1000 mox_features to reduce noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words='english', max_features=1000) # why limit to just 1000\n",
    "## this reduces the noise from 0 values\n",
    "\n",
    "#Learn our Vocab\n",
    "vect.fit(data)\n",
    "\n",
    "# Get sparse dtm\n",
    "dtm = vect.transform(data)\n",
    "\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df['description']\n",
    "vect = CountVectorizer(stop_words='english', max_features=1000)\n",
    "vect.fit(docs)\n",
    "dtm = vect.transform(docs)\n",
    "\n",
    "dtm2 = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6)\t1\n",
      "  (0, 129)\t1\n",
      "  (0, 140)\t1\n",
      "  (0, 154)\t1\n",
      "  (0, 170)\t1\n",
      "  (0, 207)\t1\n",
      "  (0, 212)\t1\n",
      "  (0, 218)\t1\n",
      "  (0, 278)\t1\n",
      "  (0, 319)\t2\n",
      "  (0, 326)\t1\n",
      "  (0, 345)\t1\n",
      "  (0, 348)\t1\n",
      "  (0, 367)\t1\n",
      "  (0, 392)\t1\n",
      "  (0, 401)\t1\n",
      "  (0, 453)\t1\n",
      "  (0, 460)\t1\n",
      "  (0, 473)\t1\n",
      "  (0, 476)\t1\n",
      "  (0, 483)\t2\n",
      "  (0, 486)\t1\n",
      "  (0, 498)\t1\n",
      "  (0, 517)\t1\n",
      "  (0, 521)\t1\n",
      "  :\t:\n",
      "  (425, 892)\t1\n",
      "  (425, 894)\t1\n",
      "  (425, 898)\t1\n",
      "  (425, 902)\t3\n",
      "  (425, 903)\t1\n",
      "  (425, 904)\t1\n",
      "  (425, 916)\t1\n",
      "  (425, 917)\t1\n",
      "  (425, 920)\t1\n",
      "  (425, 923)\t1\n",
      "  (425, 928)\t1\n",
      "  (425, 932)\t1\n",
      "  (425, 935)\t1\n",
      "  (425, 936)\t1\n",
      "  (425, 944)\t2\n",
      "  (425, 948)\t1\n",
      "  (425, 953)\t1\n",
      "  (425, 968)\t6\n",
      "  (425, 970)\t1\n",
      "  (425, 971)\t1\n",
      "  (425, 978)\t5\n",
      "  (425, 980)\t2\n",
      "  (425, 986)\t3\n",
      "  (425, 995)\t5\n",
      "  (425, 998)\t2\n"
     ]
    }
   ],
   "source": [
    "print(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word counts in matrix form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>2019</th>\n",
       "      <th>40</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>academic</th>\n",
       "      <th>access</th>\n",
       "      <th>...</th>\n",
       "      <th>xa6</th>\n",
       "      <th>xae</th>\n",
       "      <th>xb7</th>\n",
       "      <th>xbb</th>\n",
       "      <th>xc2</th>\n",
       "      <th>xe2</th>\n",
       "      <th>xef</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  10  100  2019  40  abilities  ability  able  academic  access  ...  \\\n",
       "0    0   0    0     0   0          0        1     0         0       0  ...   \n",
       "1    0   0    0     0   0          0        1     0         0       0  ...   \n",
       "2    0   0    0     0   0          0        0     0         0       0  ...   \n",
       "3    0   0    0     0   0          0        0     0         0       0  ...   \n",
       "4    0   0    0     0   0          0        0     0         0       0  ...   \n",
       "\n",
       "   xa6  xae  xb7  xbb  xc2  xe2  xef  year  years  york  \n",
       "0    0    0    0    0    1    0    0     0      0     0  \n",
       "1    2    0    0    0    0    8    0     1      0     0  \n",
       "2    0    0    0    0    0    0    0     0      0     0  \n",
       "3    0    0    0    0    0    0    0     1      0     0  \n",
       "4    0    0    0    0    0    1    0     0      1     0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "## 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data    4394\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "dtm2.sum().sort_values(ascending=False)[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use the line from above to create an sns distribution plot below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(dtm2.sum().sort_values(ascending=False)[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### based on the graph above you should consider appending 'data' to the stop words list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### whats the length of each document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_len = [len(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[837, 4011, 856, 1740, 237]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_len[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'll instantiate the tfidfVectorizer() class and use it to transform the docs variable to a TF-IDF feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>04</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1079302</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>125</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>...</th>\n",
       "      <th>years</th>\n",
       "      <th>yearthe</th>\n",
       "      <th>yes</th>\n",
       "      <th>yeti</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>yrs</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zf</th>\n",
       "      <th>zillow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000   04   10  100  1079302   11   12  125   14   15  ...     years  \\\n",
       "0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
       "1  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
       "2  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
       "3  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
       "4  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  ...  0.093431   \n",
       "\n",
       "   yearthe  yes  yeti  york  young  yrs  zeus   zf  zillow  \n",
       "0      0.0  0.0   0.0   0.0    0.0  0.0   0.0  0.0     0.0  \n",
       "1      0.0  0.0   0.0   0.0    0.0  0.0   0.0  0.0     0.0  \n",
       "2      0.0  0.0   0.0   0.0    0.0  0.0   0.0  0.0     0.0  \n",
       "3      0.0  0.0   0.0   0.0    0.0  0.0   0.0  0.0     0.0  \n",
       "4      0.0  0.0   0.0   0.0    0.0  0.0   0.0  0.0     0.0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate vectorizer object\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# Create a vocabulary and get word counts per document\n",
    "# Similiar to fit_predict\n",
    "dtm = tfidf.fit_transform(docs)\n",
    "\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
    "\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(document):\n",
    "    \"\"\"tokenizes and lemmatizes\"\"\"\n",
    "    doc = nlp(document)\n",
    "    return [token.lemma_.strip() for token in doc if (token.is_stop != True) and (token.is_punct != True)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### below, analyzes unique topics for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$</th>\n",
       "      <th>+</th>\n",
       "      <th>+ year</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>2019</th>\n",
       "      <th>3</th>\n",
       "      <th>3 year</th>\n",
       "      <th>...</th>\n",
       "      <th>write communication</th>\n",
       "      <th>write verbal</th>\n",
       "      <th>year</th>\n",
       "      <th>year experience</th>\n",
       "      <th>year professional</th>\n",
       "      <th>year relevant</th>\n",
       "      <th>year work</th>\n",
       "      <th>years\\xe2\\x80\\x99</th>\n",
       "      <th>york</th>\n",
       "      <th>you\\xe2\\x80\\x99ll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041867</td>\n",
       "      <td>0.045716</td>\n",
       "      <td>0.15787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.265893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.227397</td>\n",
       "      <td>0.248300</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.163181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1051 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          $         +    + year        1   10  100         2  2019    3  \\\n",
       "0  0.000000  0.000000  0.000000  0.00000  0.0  0.0  0.150387   0.0  0.0   \n",
       "1  0.000000  0.041867  0.045716  0.15787  0.0  0.0  0.000000   0.0  0.0   \n",
       "2  0.000000  0.000000  0.000000  0.00000  0.0  0.0  0.000000   0.0  0.0   \n",
       "3  0.265893  0.000000  0.000000  0.00000  0.0  0.0  0.000000   0.0  0.0   \n",
       "4  0.000000  0.227397  0.248300  0.00000  0.0  0.0  0.000000   0.0  0.0   \n",
       "\n",
       "   3 year  ...  write communication  write verbal      year  year experience  \\\n",
       "0     0.0  ...                  0.0           0.0  0.000000              0.0   \n",
       "1     0.0  ...                  0.0           0.0  0.030044              0.0   \n",
       "2     0.0  ...                  0.0           0.0  0.000000              0.0   \n",
       "3     0.0  ...                  0.0           0.0  0.038032              0.0   \n",
       "4     0.0  ...                  0.0           0.0  0.163181              0.0   \n",
       "\n",
       "   year professional  year relevant  year work  years\\xe2\\x80\\x99  york  \\\n",
       "0                0.0            0.0        0.0                0.0   0.0   \n",
       "1                0.0            0.0        0.0                0.0   0.0   \n",
       "2                0.0            0.0        0.0                0.0   0.0   \n",
       "3                0.0            0.0        0.0                0.0   0.0   \n",
       "4                0.0            0.0        0.0                0.0   0.0   \n",
       "\n",
       "   you\\xe2\\x80\\x99ll  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                0.0  \n",
       "\n",
       "[5 rows x 1051 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tunning Parameters\n",
    "\n",
    "# Instantiate vectorizer object\n",
    "tfidf = TfidfVectorizer(stop_words='english', \n",
    "                        ngram_range=(1,2),\n",
    "                        max_df=.97,\n",
    "                        min_df=.05,\n",
    "                        tokenizer=tokenize)\n",
    "\n",
    "# Create a vocabulary and get word counts per document\n",
    "dtm = tfidf.fit_transform(df['description']) # Similiar to fit_predict\n",
    "\n",
    "# Print word counts\n",
    "\n",
    "# Get feature names to use as dataframe column headers\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
    "\n",
    "# View Feature Matrix as DataFrame\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 1051)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Fit on DTM\n",
    "nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
    "nn.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 1.21251101, 1.2148629 , 1.22450202, 1.22539118]]),\n",
       " array([[  0, 403,  79, 345, 338]], dtype=int64))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.kneighbors([dtm.iloc[0].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 0.        , 0.84131856, 1.18311206, 1.18311206]]),\n",
       " array([[ 77, 214,  89, 181,  11]], dtype=int64))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query Using kneighbors \n",
    "nn.kneighbors([dtm.iloc[77]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'Role Summary:\\\\nThe CCS Data Scientist is responsible for supporting the CCS digital service operations teams with data analytics that drive improved remote service efficiency and improved customer e\""
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[256][:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what shall my job description be???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = [\"\"\"\n",
    "65000 junior entry data science data analyst biology agriculture denver boulder fort collins remote 401k health benefits bachelor's degree\n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = tfidf.transform(job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1051 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.15920688, 1.22271234, 1.27076096, 1.28523077, 1.28665185]]),\n",
       " array([[213, 406, 349, 201, 391]], dtype=int64))"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.kneighbors(new.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MY BEST MATCH, I guess I'm moving to Houston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'Houston Methodist (HM) is looking for passionate data scientists to join the Center for Outcomes Research (COR) to lead and develop informatics initiatives that transform healthcare via data science and informatics. The goal of the HM COR informatics initiative is to benefit patients and society as a whole by utilizing the skills and tools of data science to model patient populations clinically and economically within the context of the patient, the health care and hospital systems so that we can optimize business and clinical operations, improve patient care, reduce costs and position HM to more effectively address population health and other strategic health care needs into the future. The responsibility of the data scientist is to address the best uses of data science and informatics resources for HM clinical and business operations and patient care, including the organization\\\\xe2\\\\x80\\\\x99s needs to assess and understand clinical, financial, operational, population health and marketing data. The data scientist should leverage the information in HM enterprise data warehouses and the Epic\\\\xc2\\\\xae electronic medical record as well as contribute to, manage and maintain and adhere to data definition standards crafted by the Hospital Data Governance Council. Under the guidance and direction of the Division Chief of Healthcare Informatics within the COR, the data scientist will work closely with clinicians, care givers, hospital staff, administrators, and other stakeholders to implement projects of clinical, business and societal benefit. The projects for this role will include, but are not limited to: research study protocol design and supporting analysis, predictive analytics, crafting innovative decision support methodology, advanced analytics, outcomes measures, cost reduction, quality improvement, population health management, statistical and advanced modeling techniques applied to different types of health and meta data, and coordinate with clinicians and scientists for the development of business and scientific presentations for a variety of audiences and stakeholders. The position promotes and supports system and department specific ICARE values.\\\\nPATIENT AGE GROUP SERVED\\\\nNot applicable\\\\nDUTIES AND RESPONSIBILITIES\\\\nPEOPLE (15%)\\\\nManages client relationships as assigned, by leading the delivery of innovative strategies and solutions for our clients (EF).\\\\nPresents project progresses and results to the stakeholders.\\\\nReports to the Head of Informatics Development Department of HMH IT.\\\\n\\\\nFINANCE (10%)\\\\nApplies good fiscal management practices\\\\nManages the continuous improvement of clinical and operational data and analytics.\\\\n\\\\nQUALITY/SAFETY (20%)\\\\nBe knowledgeable on clinical data quality issues and assurance as well as patient privacy and data security and compliance.\\\\nDocuments the project requirements and results on a timely basis.\\\\n\\\\nSERVICE (35%)\\\\nDrives the data analytics insights across the hospital system.\\\\nDrives the execution of multiple analytical plans and projects.\\\\nIdentify data elements within the clinical/health databases for analytics and decision supports.\\\\nGROWTH/INNOVATION (20%)\\\\nConsults with clinicians and hospital staff regarding process improvement, delivery of best outcomes, decision supports, data insights and recommendations.\\\\nTranslates the findings into implementable informatics solutions with the clinicians, hospital administration, and other stakeholders.\\\\n\\\\nThis job description is not intended to be all inclusive; the employee will also perform other reasonably related business/job duties as assigned. Houston Methodist reserves the right to revise job duties and responsibilities as the need arises.\\\\nEDUCATION REQUIREMENTS\\\\nMaster\\\\xe2\\\\x80\\\\x99s Degree in Computer Science, Clinical Informatics, Public Health Administration, Business Administration, or Engineering, or an MD with experience in Computing, Informatics, and Statistics.\\\\nEXPERIENCE REQUIREMENTS\\\\nAt least 4 years of experience in data analytics and/or database management in a healthcare organization.\\\\nCERTIFICATES, LICENSES AND REGISTRATIONS REQUIRED\\\\nNone\\\\nKNOWLEDGE, SKILLS AND ABILITIES REQUIRED\\\\nExperience with clinical settings and healthcare administration.\\\\nExperience with statistical, database and algorithm modeling preferred.\\\\nExperience implementing and managing Health IT software prototyping and applications.\\\\nExperience in process mapping and analytics.\\\\nExperience on decision support methodology and advanced analytics.\\\\nExperience of clinical/health data integration in a health care IT environment.\\\\nGreat communications skills, both verbal and written a must \\\\xe2\\\\x80\\\\x93 especially as it pertains to communicating complicated technical concepts to non-technical stakeholders.\\\\nProven interaction skills with clinicians and hospital administrators.\\\\nSufficient proficiency in speaking, reading, and writing the English language necessary to perform the essential functions of this job, especially with regard to activities impacting patient or employee safety or security.\\\\nAbility to effectively communicate with patients, physicians, family members and co-workers in a manner consistent with a customer service focus and application of positive language principles.\\\\n\\\\nWORKING ENVIRONMENT\\\\nNormal office environment'\""
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'][213]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
    " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "U4-S1-NLP-DS17 (Python3)",
   "language": "python",
   "name": "u4-s1-nlp-ds17"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
